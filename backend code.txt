# Backend Directory Structure and Code

## Directory Structure
```
backend/
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ alembic/
â”‚   â”œâ”€â”€ env.py
â”‚   â”œâ”€â”€ script.py.mako
â”‚   â””â”€â”€ versions/
â”œâ”€â”€ alembic.ini
â”œâ”€â”€ DEPLOYMENT.md
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ todo.db
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ __pycache__/
    â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ deps.py
    â”‚   â””â”€â”€ v1/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ __pycache__/
    â”‚       â”œâ”€â”€ api.py
    â”‚       â””â”€â”€ endpoints/
    â”‚           â”œâ”€â”€ __init__.py
    â”‚           â”œâ”€â”€ __pycache__/
    â”‚           â”œâ”€â”€ agent.py
    â”‚           â”œâ”€â”€ auth.py
    â”‚           â””â”€â”€ tasks.py
    â”œâ”€â”€ core/
    â”œâ”€â”€ db/
    â”‚   â””â”€â”€ session.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ mcp/
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ task.py
    â”‚   â””â”€â”€ user.py
    â”œâ”€â”€ schemas/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ task.py
    â””â”€â”€ utils/
```

## File Contents

### backend/.env
```
# Database
DATABASE_URL=sqlite:///./todo.db
# For production, use a proper database URL like:
# DATABASE_URL=postgresql://user:password@localhost/dbname

# JWT
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# OpenAI
OPENAI_API_KEY=your-openai-api-key-here

# Better Auth
AUTH_SECRET=your-auth-secret-here
```

### backend/.env.example
```
# Database
DATABASE_URL=sqlite:///./todo.db

# JWT
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# OpenAI
OPENAI_API_KEY=your-openai-api-key-here

# Better Auth
AUTH_SECRET=your-auth-secret-here
```

### backend/requirements.txt
```
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlmodel==0.0.16
python-jose[cryptography]==3.3.0
bcrypt==4.1.1
passlib==1.7.4
alembic==1.13.1
python-dotenv==1.0.0
pytest==7.4.3
httpx==0.25.2
pydantic-settings==2.1.0
aiosqlite==0.19.0
asyncpg==0.29.0
PyJWT
psycopg2-binary
openai>=1.0.0
```

### backend/src/main.py
```
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from .api.v1.api import router as api_router
from .api.v1.endpoints.agent import router as agent_router
import os
from dotenv import load_dotenv
from sqlmodel import SQLModel
from .db.session import sync_engine
from .models.user import User
from .models.task import Task

# Load environment variables
load_dotenv()

# Create database tables on startup
def create_db_and_tables():
    SQLModel.metadata.create_all(sync_engine)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Create tables on startup
    create_db_and_tables()
    yield
    # Cleanup on shutdown if needed

app = FastAPI(
    title="Professional Todo Manager API",
    description="API for the Professional Todo Manager backend service",
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware to allow requests from localhost:3000
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],  # Frontend URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include API routers
app.include_router(api_router, prefix="/api/v1")
app.include_router(agent_router, prefix="/api/v1", tags=["agent"])

@app.get("/")
def read_root():
    return {"message": "Professional Todo Manager API"}

@app.get("/health")
def health_check():
    return {"status": "healthy"}
```

### backend/src/api/deps.py
```
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt
from jwt import PyJWTError
from sqlmodel import Session
from typing import Generator
from datetime import datetime, timedelta
from dotenv import load_dotenv
import os

from ..db.session import get_session
from ..models.user import User

load_dotenv()

# Security scheme
security = HTTPBearer()

# JWT configuration
SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key-here")
ALGORITHM = os.getenv("ALGORITHM", "HS256")
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "30"))

def create_access_token(data: dict, expires_delta: timedelta = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(token: str) -> dict:
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Could not validate credentials",
                headers={"WWW-Authenticate": "Bearer"},
            )
        return payload
    except PyJWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security),
    session: Session = Depends(get_session)
) -> User:
    token = credentials.credentials
    payload = verify_token(token)
    user_id = payload.get("sub")

    if user_id is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

    user = session.get(User, user_id)
    if user is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="User not found",
            headers={"WWW-Authenticate": "Bearer"},
        )

    return user
```

### backend/src/api/v1/api.py
```
from fastapi import APIRouter
from .endpoints import auth, tasks, agent

router = APIRouter()

# Include all API endpoints
router.include_router(auth.router, prefix="/auth", tags=["authentication"])
router.include_router(tasks.router, prefix="/tasks", tags=["tasks"])
router.include_router(agent.router, prefix="", tags=["agent"])
```

### backend/src/api/v1/endpoints/tasks.py
```
from fastapi import APIRouter, Depends, HTTPException, status
from sqlmodel import Session, select, func
from typing import List
from datetime import datetime, timedelta, timezone
import uuid

from src.db.session import get_session
from src.models.user import User
from src.models.task import Task, TaskStatus
from src.schemas.task import TaskCreate, TaskRead, TaskUpdate, DashboardStats
from src.api.deps import get_current_user

router = APIRouter()

# --- NEW STATS ENDPOINT ---
@router.get("/stats", response_model=DashboardStats)
def get_dashboard_stats(
    current_user: User = Depends(get_current_user),
    session: Session = Depends(get_session)
):
    # Get current time once to avoid time drift during execution
    # Using timezone-aware datetime for proper comparison
    now = datetime.now(timezone.utc)
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    seven_days_later = now + timedelta(days=7)

    # Execute multiple efficient queries in parallel
    total_tasks = session.exec(
        select(func.count(Task.id)).where(Task.user_id == current_user.id)
    ).one()

    completed_tasks = session.exec(
        select(func.count(Task.id)).where(
            Task.user_id == current_user.id,
            Task.status == TaskStatus.completed
        )
    ).one()

    completed_today = session.exec(
        select(func.count(Task.id)).where(
            Task.user_id == current_user.id,
            Task.status == TaskStatus.completed,
            Task.updated_at >= today_start
        )
    ).one()

    # Fixed: Compare only date parts for due soon calculation to handle timezone issues
    # Also ensure due date is not in the past
    tasks_due_soon = session.exec(
        select(func.count(Task.id)).where(
            Task.user_id == current_user.id,
            Task.status == TaskStatus.pending,
            Task.due_date != None,
            Task.due_date >= now,  # Due date should not be in the past
            Task.due_date <= seven_days_later  # Due date should be within 7 days
        )
    ).one()

    # Calculate productivity score
    productivity_score = 0
    if total_tasks > 0:
        productivity_score = round((completed_tasks / total_tasks) * 100)

    return DashboardStats(
        tasks_due_soon=tasks_due_soon,
        completed_today=completed_today,
        productivity_score=productivity_score,
        total_tasks=total_tasks,
        completed_tasks=completed_tasks
    )
# --------------------------

@router.get("/", response_model=List[TaskRead])
def list_user_tasks(
    current_user: User = Depends(get_current_user),
    session: Session = Depends(get_session)
):
    tasks = session.exec(select(Task).where(Task.user_id == current_user.id)).all()
    return tasks

@router.post("/", response_model=TaskRead, status_code=status.HTTP_201_CREATED)
def create_task(
    task_create: TaskCreate,
    current_user: User = Depends(get_current_user),
    session: Session = Depends(get_session)
):
    db_task = Task(
        user_id=current_user.id,
        title=task_create.title,
        description=task_create.description,
        status=task_create.status,
        priority=task_create.priority,
        due_date=task_create.due_date,
        tags=task_create.tags,
        created_at=datetime.utcnow(),
        updated_at=datetime.utcnow()
    )
    session.add(db_task)
    session.commit()
    session.refresh(db_task)
    return db_task

@router.get("/{task_id}", response_model=TaskRead)
def get_task(
    task_id: uuid.UUID,
    current_user: User = Depends(get_current_user),
    session: Session = Depends(get_session)
):
    task = session.get(Task, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    if task.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not authorized")
    return task

@router.put("/{task_id}", response_model=TaskRead)
def update_task(
    task_id: uuid.UUID,
    task_update: TaskUpdate,
    current_user: User = Depends(get_current_user),
    session: Session = Depends(get_session)
):
    task = session.get(Task, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    if task.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not authorized")

    task_data = task_update.dict(exclude_unset=True)
    for key, value in task_data.items():
        setattr(task, key, value)

    task.updated_at = datetime.utcnow()
    session.add(task)
    session.commit()
    session.refresh(task)
    return task

@router.delete("/{task_id}")
def delete_task(
    task_id: uuid.UUID,
    current_user: User = Depends(get_current_user),
    session: Session = Depends(get_session)
):
    task = session.get(Task, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    if task.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not authorized")

    session.delete(task)
    session.commit()
    return {"ok": True}
```

### backend/src/api/v1/endpoints/auth.py
```
from fastapi import APIRouter, Depends, HTTPException, status
from sqlmodel import Session, select
from typing import Optional
from datetime import timedelta
import uuid
from pydantic import BaseModel

from src.db.session import get_session
from src.models.user import User
from src.schemas.user import UserCreate, UserRead
from src.api.deps import get_current_user, create_access_token
from src.utils.security import verify_password, get_password_hash

router = APIRouter()

class Token(BaseModel):
    access_token: str
    token_type: str

class LoginRequest(BaseModel):
    email: str
    password: str

@router.post("/register", response_model=UserRead)
def register(user_create: UserCreate, session: Session = Depends(get_session)):
    # Check if user already exists
    existing_user = session.exec(select(User).where(User.email == user_create.email)).first()
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User with this email already exists"
        )

    # Create new user
    hashed_password = get_password_hash(user_create.password)
    db_user = User(
        email=user_create.email,
        full_name=user_create.full_name,
        hashed_password=hashed_password,
        created_at=user_create.created_at if hasattr(user_create, 'created_at') else None
    )

    session.add(db_user)
    session.commit()
    session.refresh(db_user)

    return db_user

@router.post("/login", response_model=Token)
def login(login_request: LoginRequest, session: Session = Depends(get_session)):
    # Find user by email
    user = session.exec(select(User).where(User.email == login_request.email)).first()

    if not user or not verify_password(login_request.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create access token
    access_token_expires = timedelta(minutes=30)  # You can make this configurable
    access_token = create_access_token(
        data={"sub": str(user.id)}, expires_delta=access_token_expires
    )

    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/me", response_model=UserRead)
def read_current_user(current_user: User = Depends(get_current_user)):
    return current_user
```

### backend/src/models/task.py
```
from sqlmodel import SQLModel, Field, Relationship
from typing import Optional
from datetime import datetime
import uuid
from enum import Enum


class TaskStatus(str, Enum):
    pending = "pending"
    completed = "completed"
    archived = "archived"


class TaskPriority(str, Enum):
    low = "low"
    medium = "medium"
    high = "high"


class Task(SQLModel, table=True):
    __tablename__ = "tasks"

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    user_id: uuid.UUID = Field(foreign_key="users.id", nullable=False)
    title: str = Field(nullable=False)
    description: Optional[str] = Field(default=None)
    status: TaskStatus = Field(default=TaskStatus.pending)
    priority: TaskPriority = Field(default=TaskPriority.medium)
    due_date: Optional[datetime] = Field(default=None)

    # --- ADDED TAGS FIELD ---
    tags: Optional[str] = Field(default=None, nullable=True)
    # ------------------------

    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow, nullable=False)

    # Relationship to user
    user: Optional["User"] = Relationship(back_populates="tasks")
```

### backend/src/models/user.py
```
from sqlmodel import SQLModel, Field, Relationship
from typing import Optional, List
from datetime import datetime
import uuid


class User(SQLModel, table=True):
    __tablename__ = "users"

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    email: str = Field(unique=True, nullable=False)
    full_name: str
    hashed_password: str = Field(nullable=False)
    created_at: datetime = Field(default_factory=datetime.utcnow)

    # Relationship to tasks
    tasks: List["Task"] = Relationship(back_populates="user")
```

### backend/src/schemas/task.py
```
from sqlmodel import SQLModel
from typing import Optional
from datetime import datetime
import uuid
from enum import Enum
from ..models.task import TaskStatus, TaskPriority

class TaskBase(SQLModel):
    title: str
    description: Optional[str] = None
    status: Optional[TaskStatus] = TaskStatus.pending
    priority: Optional[TaskPriority] = TaskPriority.medium
    due_date: Optional[datetime] = None
    tags: Optional[str] = None

class TaskCreate(TaskBase):
    title: str

class TaskRead(TaskBase):
    id: uuid.UUID
    user_id: uuid.UUID
    created_at: datetime
    updated_at: datetime

class TaskUpdate(SQLModel):
    title: Optional[str] = None
    description: Optional[str] = None
    status: Optional[TaskStatus] = None
    priority: Optional[TaskPriority] = None
    due_date: Optional[datetime] = None
    tags: Optional[str] = None

# --- NEW STATS SCHEMA ---
class DashboardStats(SQLModel):
    tasks_due_soon: int
    completed_today: int
    productivity_score: int
    total_tasks: int
    completed_tasks: int
```

### backend/src/db/session.py
```
from sqlmodel import create_engine, Session
from dotenv import load_dotenv
import os

load_dotenv()

# Database URL from environment
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./todo.db")

# Create engines
sync_engine = create_engine(DATABASE_URL, echo=True)

def get_session():
    with Session(sync_engine) as session:
        yield session
```

### backend/alembic.ini
```
# A generic, single database configuration.

[alembic]
# path to migration scripts
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to zoneinfo.ZoneInfo() or backports.zoneinfo.ZoneInfo()
# leave blank for "local" time
# timezone =

# max length of characters to apply to the
# "slug" field
# max_length = 40

# version_numter -> version path mapping
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is defaulted
# to os.pathsep, however on Windows, you may want to specify either
# "/" or "." as your path separator, e.g.
# version_path_separator = /
# version_path_separator = .

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by the
# version_path_separator setting; if the version_path_separator is not
# specified or left to the default, the path separator is the platform
# separator (the os.pathsep constant).
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

sqlalchemy.url = driver://user:pass@localhost/dbname


[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

### Additional Backend Files

### backend/src/core/security.py
```
from datetime import datetime, timedelta
from typing import Optional
import jwt
from passlib.context import CryptContext
from fastapi import HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlmodel import Session, select
from .config import settings
from ..models.user import User
from ..db.session import get_async_session
from ..schemas.user import TokenData
from fastapi import Depends
from sqlalchemy.ext.asyncio import AsyncSession

# Password hashing context
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# JWT authentication scheme
security = HTTPBearer()

# JWT token functions
def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)

    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt


def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)


def get_password_hash(password: str) -> str:
    return pwd_context.hash(password)


async def authenticate_user(session: AsyncSession, email: str, password: str) -> Optional[User]:
    # Find user by email
    statement = select(User).where(User.email == email)
    result = await session.execute(statement)
    user = result.first()

    if user is None:
        return None

    user = user[0]  # Get the User object from the tuple

    if not verify_password(password, user.password_hash):
        return None

    return user


async def get_current_user(
    token: HTTPAuthorizationCredentials = Depends(security),
    session: AsyncSession = Depends(get_async_session)
) -> User:
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    try:
        payload = jwt.decode(
            token.credentials, settings.SECRET_KEY, algorithms=[settings.ALGORITHM]
        )
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
        token_data = TokenData(username=username)
    except jwt.exceptions.PyJWTError:
        raise credentials_exception

    statement = select(User).where(User.email == token_data.username)
    result = await session.execute(statement)
    user = result.first()

    if user is None:
        raise credentials_exception

    return user[0]  # Return the User object from the tuple
```

### backend/src/core/config.py
```
from pydantic_settings import BaseSettings
from typing import Optional
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class Settings(BaseSettings):
    # Database settings
    DATABASE_URL: str = os.getenv("DATABASE_URL", "sqlite+aiosqlite:///./todo.db")

    # JWT settings
    SECRET_KEY: str = os.getenv("SECRET_KEY", "your-super-secret-key-change-in-production")
    ALGORITHM: str = os.getenv("ALGORITHM", "HS256")
    ACCESS_TOKEN_EXPIRE_MINUTES: int = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "30"))

    # Better Auth settings
    BETTER_AUTH_SECRET: str = os.getenv("BETTER_AUTH_SECRET", "your-better-auth-secret-change-in-production")

    # Project settings
    PROJECT_NAME: str = os.getenv("PROJECT_NAME", "Todo App Phase II")
    API_V1_STR: str = "/api/v1"

    # --- ðŸ‘‡ ADD THIS SECTION FOR PHASE 3 ðŸ‘‡ ---
    # This tells Pydantic: "It is okay if OPENAI_API_KEY exists in .env, load it here."
    OPENAI_API_KEY: Optional[str] = os.getenv("OPENAI_API_KEY")

    class Config:
        env_file = ".env"
        # This prevents the error "Extra inputs are not permitted"
        # It allows variables in .env that aren't defined here to simply be ignored.
        extra = "ignore"

settings = Settings()
```

### backend/src/schemas/user.py
```
from sqlmodel import SQLModel
from typing import Optional
from datetime import datetime
import uuid


class UserBase(SQLModel):
    email: str
    full_name: str


class UserCreate(UserBase):
    password: str


class UserRead(UserBase):
    id: uuid.UUID
    created_at: datetime


class UserUpdate(SQLModel):
    email: Optional[str] = None
    full_name: Optional[str] = None


class UserLogin(SQLModel):
    email: str
    password: str


class Token(SQLModel):
    access_token: str
    token_type: str


class TokenData(SQLModel):
    username: Optional[str] = None
```

### backend/alembic/env.py
```
from logging.config import fileConfig
import sys
import os
from pathlib import Path
from dotenv import load_dotenv

# 1. Force load the .env file
env_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(env_path)

# Add the project root to the path
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import engine_from_config
from sqlalchemy import pool
from sqlalchemy.engine import Connection

from alembic import context

# IMPORT MODELS SO ALEMBIC SEES THEM - import from models package to resolve circular references
from src import models
from sqlmodel import SQLModel

config = context.config

# 2. OVERRIDE URL with .env variable - use sync version for migrations
database_url = os.getenv("DATABASE_URL")
if database_url:
    # Convert async database URL to sync for migrations
    sync_database_url = database_url.replace("+aiosqlite", "").replace("+asyncpg", "")
    config.set_main_option("sqlalchemy.url", sync_database_url)

if config.config_file_name is not None:
    fileConfig(config.config_file_name)

target_metadata = SQLModel.metadata

def run_migrations_offline() -> None:
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def do_run_migrations(connection: Connection) -> None:
    context.configure(connection=connection, target_metadata=target_metadata)

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online() -> None:
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        do_run_migrations(connection)

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

### backend/alembic/versions/6d002353537a_initial_migration.py
```
"""Initial migration

Revision ID: 6d002353537a
Revises:
Create Date: 2026-01-03 02:05:59.502986

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel


# revision identifiers, used by Alembic.
revision: str = '6d002353537a'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sqlmodel.sql.sqltypes.GUID(), nullable=False),
    sa.Column('email', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('password_hash', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('full_name', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_table('tasks',
    sa.Column('id', sqlmodel.sql.sqltypes.GUID(), nullable=False),
    sa.Column('user_id', sqlmodel.sql.sqltypes.GUID(), nullable=False),
    sa.Column('title', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
    sa.Column('description', sqlmodel.sql.sqltypes.AutoString(), nullable=True),
    sa.Column('status', sa.Enum('pending', 'completed', 'archived', name='taskstatus'), nullable=False),
    sa.Column('priority', sa.Enum('low', 'medium', 'high', name='taskpriority'), nullable=False),
    sa.Column('due_date', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('tasks')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    # ### end Alembic commands ###
```

### backend/src/mcp/tools.py
```
from sqlmodel import Session, select
from datetime import datetime
from typing import Optional
import datetime as dt
from uuid import UUID

# Ensure these imports match your project structure
from ..models.task import Task
from ..models.user import User
from ..db.session import sync_engine

def add_task(user_id: str, title: str, description: Optional[str] = None,
             priority: str = "medium", due_date: Optional[str] = None, tags: Optional[str] = None):
    """
    Add a new task to the user's task list
    """
    with Session(sync_engine) as session:
        if not user_id:
            raise ValueError("user_id is required")

        parsed_due_date = None
        if due_date:
            try:
                parsed_due_date = dt.datetime.strptime(due_date, "%Y-%m-%d")
            except ValueError:
                for fmt in ("%Y-%m-%dT%H:%M:%S", "%Y-%m-%d %H:%M:%S"):
                    try:
                        parsed_due_date = dt.datetime.strptime(due_date, fmt)
                        break
                    except ValueError:
                        continue
                if parsed_due_date is None:
                    # Fallback: if date parsing fails, just leave it None or log warning
                    pass

        task = Task(
            user_id=user_id,
            title=title,
            description=description,
            priority=priority,
            due_date=parsed_due_date,
            tags=tags,
            status="pending"
        )
        session.add(task)
        session.commit()
        session.refresh(task)

        return {
            "status": "success",
            "message": f"Task '{title}' added successfully.",
            "task": {
                "id": str(task.id),
                "title": task.title,
                "status": task.status
            }
        }

def list_tasks(user_id: str, status: Optional[str] = None):
    """
    List tasks for the user with optional filtering
    """
    with Session(sync_engine) as session:
        if not user_id:
            raise ValueError("user_id is required")

        query = select(Task).where(Task.user_id == user_id)

        if status and status != "all":
            query = query.where(Task.status == status)

        tasks = session.exec(query).all()

        task_list = []
        for task in tasks:
            task_dict = {
                "id": str(task.id),
                "title": task.title,
                "description": task.description,
                "priority": task.priority,
                "status": task.status,
                "due_date": task.due_date.isoformat() if task.due_date else None,
                "created_at": task.created_at.isoformat() if task.created_at else None
            }
            task_list.append(task_dict)

        return {
            "status": "success",
            "tasks": task_list,
            "user_id": user_id,
            "filter_applied": status
        }

def delete_task(user_id: str, task_title: str):
    """
    Delete a task from the user's task list
    """
    with Session(sync_engine) as session:
        if not user_id:
            raise ValueError("user_id is required")
        if not task_title:
            raise ValueError("task_title is required")

        query = select(Task).where(Task.user_id == user_id).where(Task.title == task_title)
        task = session.exec(query).first()

        if not task:
            return {"status": "error", "message": f"Task '{task_title}' not found."}

        session.delete(task)
        session.commit()

        return {
            "status": "success",
            "message": f"Task '{task_title}' deleted successfully."
        }

def get_analytics(user_id: str):
    """
    Get analytics data for the user
    """
    with Session(sync_engine) as session:
        if not user_id:
            raise ValueError("user_id is required")

        all_tasks_query = select(Task).where(Task.user_id == user_id)
        all_tasks = session.exec(all_tasks_query).all()

        total_tasks = len(all_tasks)
        completed_tasks = len([task for task in all_tasks if task.status == "completed"])
        pending_tasks = len([task for task in all_tasks if task.status == "pending"])

        overdue_tasks = 0
        now = dt.datetime.now()
        for task in all_tasks:
            if task.status != "completed" and task.due_date and task.due_date < now:
                overdue_tasks += 1

        productivity_score = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0

        return {
            "status": "success",
            "analytics": {
                "tasks_total": total_tasks,
                "tasks_completed": completed_tasks,
                "tasks_pending": pending_tasks,
                "tasks_overdue": overdue_tasks,
                "productivity_score": round(productivity_score, 2),
            }
        }

# --- NEW UPDATE FUNCTION ---
def update_task_by_title(
    user_id: str,
    current_title: str,
    new_title: Optional[str] = None,
    description: Optional[str] = None,
    priority: Optional[str] = None,
    status: Optional[str] = None,
    due_date: Optional[str] = None,
    tags: Optional[str] = None
):
    """
    Update an existing task by its title.
    """
    with Session(sync_engine) as session:
        if not user_id or not current_title:
            return {"status": "error", "message": "User ID and Current Title are required."}

        # 1. Find the task
        query = select(Task).where(Task.user_id == user_id).where(Task.title == current_title)
        task = session.exec(query).first()

        if not task:
            return {"status": "error", "message": f"Task '{current_title}' not found."}

        # 2. Update fields if provided
        if new_title: task.title = new_title
        if description: task.description = description
        if priority: task.priority = priority
        if status: task.status = status
        if tags: task.tags = tags

        # Handle date parsing
        if due_date:
             try:
                task.due_date = dt.datetime.strptime(due_date, "%Y-%m-%d")
             except:
                pass

        task.updated_at = dt.datetime.utcnow()

        # 3. Save to DB
        session.add(task)
        session.commit()
        session.refresh(task)

        return {
            "status": "success",
            "message": f"Task '{current_title}' updated successfully.",
            "task": {"title": task.title, "status": task.status}
        }
```

### backend/src/api/v1/endpoints/agent.py
```
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uuid
import datetime
import os
import json
from sqlmodel import Session, select, desc
from openai import OpenAI

# Internal Imports
from src.db.session import sync_engine
from src.models.chat import Conversation, ChatMessage
from src.mcp.tools import add_task, list_tasks, delete_task, get_analytics, delete_all_tasks, complete_all_tasks, mark_all_tasks_incomplete

router = APIRouter()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")  # Allow model to be configured via environment variable

# --- REQUEST/RESPONSE MODELS ---
class ChatRequest(BaseModel):
    message: str
    user_id: str
    conversation_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    conversation_id: str
    user_id: str
    tool_calls_executed: bool
    original_request: Dict[str, Any]

# --- SYSTEM PROMPT ---
SYSTEM_PROMPT = """
You are Aurora, an intelligent Task Orchestrator.
Your goal is to ensure the user stays organized and productive.

Today's date is: {current_date}

BEHAVIORAL GUIDELINES:
1. **Direct & Action-Oriented**: Do not explain what you are doing, just do it.
2. **Smart Parsing**: If the user provides a relative date like "next friday", calculate the specific date.
3. **Data Integrity**: Always ensure dates are formatted as YYYY-MM-DD before saving.
4. **Priority**: Default to "medium" if not specified.
"""

# --- TOOLS SCHEMA ---
TOOLS_SCHEMA = [
    {
        "type": "function",
        "function": {
            "name": "add_task",
            "description": "Add a new task",
            "parameters": {
                "type": "object",
                "properties": {
                    "title": {"type": "string", "description": "Task title"},
                    "description": {"type": "string", "description": "Task description"},
                    "priority": {"type": "string", "enum": ["low", "medium", "high"], "description": "Task priority"},
                    "due_date": {"type": "string", "description": "Due date in YYYY-MM-DD format"},
                    "tags": {"type": "string", "description": "Comma-separated tags"}
                },
                "required": ["title", "user_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "list_tasks",
            "description": "List tasks for the user",
            "parameters": {
                "type": "object",
                "properties": {
                    "status": {"type": "string", "enum": ["all", "pending", "completed", "archived"]}
                }
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "delete_task",
            "description": "Delete a task by title",
            "parameters": {
                "type": "object",
                "properties": {
                    "task_title": {"type": "string", "description": "Title of the task to delete"}
                },
                "required": ["task_title", "user_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "delete_all_tasks",
            "description": "Delete all tasks for the user",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": ["user_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "complete_all_tasks",
            "description": "Mark all tasks as completed for the user",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": ["user_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_analytics",
            "description": "Get analytics data for the user",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": ["user_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "mark_all_tasks_incomplete",
            "description": "Mark all tasks as incomplete for the user",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": ["user_id"]
            }
        }
    }
]

# --- CHAT ENDPOINT ---
@router.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    Handles user chat, saves to DB, calls OpenAI with tools, returns response.
    """
    if not request.user_id:
        raise HTTPException(status_code=400, detail="user_id is required")

    # A. Setup Database Session & User
    with Session(sync_engine) as session:
        try:
            user_uuid = uuid.UUID(request.user_id)
        except ValueError:
            raise HTTPException(status_code=400, detail="Invalid user_id format")

        # B. Get or Create Conversation
        conv_id = None
        if request.conversation_id:
            try:
                conv_id = uuid.UUID(request.conversation_id)
                conversation = session.get(Conversation, conv_id)
                if not conversation:
                    conv_id = None  # Fallback to new if ID not found
            except ValueError:
                conv_id = None

        if not conv_id:
            # Create new conversation title from first 30 chars
            title_text = request.message[:30] + "..." if len(request.message) > 30 else request.message
            new_conv = Conversation(
                user_id=user_uuid,
                title=title_text or "New Chat"
            )
            session.add(new_conv)
            session.commit()
            session.refresh(new_conv)
            conv_id = new_conv.id

        # C. Save USER Message to DB
        user_msg_db = ChatMessage(
            conversation_id=conv_id,
            role="user",
            content=request.message,
            created_at=datetime.datetime.utcnow()
        )
        session.add(user_msg_db)
        session.commit()

        # D. Build Context (Load history for THIS conversation only)
        from datetime import date
        today_str = date.today().strftime("%Y-%m-%d")
        messages = [{"role": "system", "content": SYSTEM_PROMPT.format(current_date=today_str)}]

        # Load conversation history
        history = session.exec(
            select(ChatMessage)
            .where(ChatMessage.conversation_id == conv_id)
            .order_by(ChatMessage.timestamp)
            .limit(10)
        ).all()

        for h in history:
            if h.role in ["user", "assistant"]:
                messages.append({"role": h.role, "content": h.content})

        # E. Call OpenAI with tools
        tool_calls_executed = False
        try:
            completion = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=messages,
                tools=TOOLS_SCHEMA,
                tool_choice="auto"
            )
            ai_msg = completion.choices[0].message

            final_resp = ""

            # F. Handle Tool Calls
            if ai_msg.tool_calls:
                messages.append(ai_msg)
                tool_calls_executed = True

                for tool_call in ai_msg.tool_calls:
                    fname = tool_call.function.name
                    args = json.loads(tool_call.function.arguments)

                    # Add user_id to arguments if not present
                    args['user_id'] = request.user_id

                    # Call the appropriate tool
                    if fname == "add_task":
                        result = add_task(**args)
                    elif fname == "list_tasks":
                        result = list_tasks(**args)
                    elif fname == "delete_task":
                        result = delete_task(**args)
                    elif fname == "delete_all_tasks":
                        result = delete_all_tasks(**args)
                    elif fname == "complete_all_tasks":
                        result = complete_all_tasks(**args)
                    elif fname == "mark_all_tasks_incomplete":
                        result = mark_all_tasks_incomplete(**args)
                    elif fname == "get_analytics":
                        result = get_analytics(**args)
                    else:
                        result = {"status": "error", "message": f"Tool {fname} not found"}

                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(result)
                    })

                # Get final response from OpenAI after tool calls
                final_completion = client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=messages
                )
                final_resp = final_completion.choices[0].message.content
            else:
                final_resp = ai_msg.content or "Okay."

        except Exception as e:
            final_resp = f"I encountered an error processing your request: {str(e)}"
            tool_calls_executed = False

        # G. Save ASSISTANT Message to DB
        ai_msg_db = ChatMessage(
            conversation_id=conv_id,
            role="assistant",
            content=final_resp or "Processed.",
            created_at=datetime.datetime.utcnow()
        )
        session.add(ai_msg_db)
        session.commit()

        # H. Return Response
        return ChatResponse(
            response=final_resp or "Done.",
            conversation_id=str(conv_id),
            user_id=request.user_id,
            tool_calls_executed=tool_calls_executed,
            original_request={"message": request.message}
        )


# --- CONVERSATION HISTORY ENDPOINTS ---
class ConversationHistoryResponse(BaseModel):
    id: str
    title: str
    created_at: datetime.datetime
    updated_at: datetime.datetime


@router.get("/conversations", response_model=List[ConversationHistoryResponse])
def get_conversations(user_id: str):
    """
    Get all conversations for a user
    """
    if not user_id:
        raise HTTPException(status_code=400, detail="user_id is required")

    with Session(sync_engine) as session:
        try:
            user_uuid = uuid.UUID(user_id)
        except ValueError:
            raise HTTPException(status_code=400, detail="Invalid user_id format")

        # Get all conversations for the user, newest first
        conversations = session.exec(
            select(Conversation)
            .where(Conversation.user_id == user_uuid)
            .order_by(desc(Conversation.updated_at))
        ).all()

        return [
            ConversationHistoryResponse(
                id=str(conv.id),
                title=conv.title,
                created_at=conv.created_at,
                updated_at=conv.updated_at
            )
            for conv in conversations
        ]


class ConversationDetailResponse(BaseModel):
    id: str
    title: str
    created_at: datetime.datetime
    updated_at: datetime.datetime
    messages: List[Dict[str, Any]]


@router.get("/conversations/{conversation_id}", response_model=ConversationDetailResponse)
def get_conversation_detail(conversation_id: str, user_id: str):
    """
    Get details of a specific conversation with all its messages
    """
    if not user_id:
        raise HTTPException(status_code=400, detail="user_id is required")

    with Session(sync_engine) as session:
        try:
            user_uuid = uuid.UUID(user_id)
            conv_uuid = uuid.UUID(conversation_id)
        except ValueError:
            raise HTTPException(status_code=400, detail="Invalid user_id or conversation_id format")

        # Get the conversation for the user
        conversation = session.get(Conversation, conv_uuid)
        if not conversation or str(conversation.user_id) != user_id:
            raise HTTPException(status_code=404, detail="Conversation not found")

        # Get all messages in the conversation
        messages = session.exec(
            select(ChatMessage)
            .where(ChatMessage.conversation_id == conv_uuid)
            .order_by(ChatMessage.timestamp.asc())
        ).all()

        return ConversationDetailResponse(
            id=str(conversation.id),
            title=conversation.title,
            created_at=conversation.created_at,
            updated_at=conversation.updated_at,
            messages=[
                {
                    "id": str(msg.id),
                    "role": msg.role,
                    "content": msg.content,
                    "timestamp": msg.timestamp
                }
                for msg in messages
            ]
        )


@router.delete("/conversations/{conversation_id}")
def delete_conversation(conversation_id: str, user_id: str):
    """
    Delete a specific conversation
    """
    if not user_id:
        raise HTTPException(status_code=400, detail="user_id is required")

    with Session(sync_engine) as session:
        try:
            user_uuid = uuid.UUID(user_id)
            conv_uuid = uuid.UUID(conversation_id)
        except ValueError:
            raise HTTPException(status_code=400, detail="Invalid user_id or conversation_id format")

        # Get the conversation for the user
        conversation = session.get(Conversation, conv_uuid)
        if not conversation or str(conversation.user_id) != user_id:
            raise HTTPException(status_code=404, detail="Conversation not found")

        # Delete all messages in the conversation first (due to foreign key constraint)
        messages = session.exec(
            select(ChatMessage)
            .where(ChatMessage.conversation_id == conv_uuid)
        ).all()

        for message in messages:
            session.delete(message)

        # Delete the conversation
        session.delete(conversation)
        session.commit()

        return {"message": "Conversation deleted successfully"}
```

### backend/src/models/chat.py
```
import uuid
from datetime import datetime
from typing import List, Optional
from sqlmodel import SQLModel, Field, Relationship

# --- 1. CONVERSATION MODEL ---
class Conversation(SQLModel, table=True):
    __tablename__ = "conversations"  # Explicit table name prevents naming conflicts

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    user_id: uuid.UUID = Field(index=True)
    title: str = Field(default="New Chat", max_length=200)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

    # Relationship: One Conversation has many Messages
    messages: List["ChatMessage"] = Relationship(back_populates="conversation")


# --- 2. CHAT MESSAGE MODEL ---
class ChatMessage(SQLModel, table=True):
    __tablename__ = "chat_messages"  # Explicit table name

    id: uuid.UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    conversation_id: uuid.UUID = Field(foreign_key="conversations.id", index=True)

    # FIX: Removed the 'check' constraint that was crashing the app
    role: str = Field(default="user")

    content: str = Field(max_length=10000)
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    tool_call_id: Optional[str] = Field(default=None)

    # Relationship: Many Messages belong to one Conversation
    conversation: Optional[Conversation] = Relationship(back_populates="messages")
```

### backend/src/api/v1/endpoints/auth.py
```
from fastapi import APIRouter, Depends, HTTPException, status
from sqlmodel import Session, select
from typing import Optional
from datetime import timedelta
import uuid
from pydantic import BaseModel

from src.db.session import get_session
from src.models.user import User
from src.schemas.user import UserCreate, UserRead
from src.api.deps import get_current_user, create_access_token
from src.utils.security import verify_password, get_password_hash

router = APIRouter()

class Token(BaseModel):
    access_token: str
    token_type: str

class LoginRequest(BaseModel):
    email: str
    password: str

@router.post("/register", response_model=UserRead)
def register(user_create: UserCreate, session: Session = Depends(get_session)):
    # Check if user already exists
    existing_user = session.exec(select(User).where(User.email == user_create.email)).first()
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User with this email already exists"
        )

    # Create new user
    hashed_password = get_password_hash(user_create.password)
    db_user = User(
        email=user_create.email,
        full_name=user_create.full_name,
        hashed_password=hashed_password,
        created_at=user_create.created_at if hasattr(user_create, 'created_at') else None
    )

    session.add(db_user)
    session.commit()
    session.refresh(db_user)

    return db_user

@router.post("/login", response_model=Token)
def login(login_request: LoginRequest, session: Session = Depends(get_session)):
    # Find user by email
    user = session.exec(select(User).where(User.email == login_request.email)).first()

    if not user or not verify_password(login_request.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Create access token
    access_token_expires = timedelta(minutes=30)  # You can make this configurable
    access_token = create_access_token(
        data={"sub": str(user.id)}, expires_delta=access_token_expires
    )

    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/me", response_model=UserRead)
def read_current_user(current_user: User = Depends(get_current_user)):
    return current_user
```

```
